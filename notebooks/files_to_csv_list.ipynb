{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b10810-1920-4850-9d9a-52264308dbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and variables names\n",
    "from google.cloud import storage\n",
    "import pandas as pd\n",
    "bucket_name = \"team4-project\"\n",
    "my_prefix='imgs/euro/'\n",
    "#Files to be created\n",
    "full_dataset_name='full_list2.csv' # The full list of images and their catagory\n",
    "train_dataset_name='train_set2.csv' # 80% to train on\n",
    "eval_dataset_name='eval_set2.csv' # 10% to eval the training on each epoch\n",
    "test_dataset_name='test_set2.csv' # 10% to test the model at the end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89693f77-c7cd-4701-b43b-47a3d7f0ad39",
   "metadata": {},
   "source": [
    "## Get full List of File Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab7d70b6-04fe-40e3-b284-fd77e4289607",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "blobs_all = list(bucket.list_blobs(prefix=my_prefix))\n",
    "gcs_data = []\n",
    "\n",
    "for x in blobs_all:\n",
    "    #Select only image files\n",
    "    if x.name.endswith(('.png','.jpg','.jpeg')):\n",
    "        gcs_data.append(['gs://'+bucket_name+'/'+x.name,x.name.split('/')[-2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2110735-87fb-4548-96dd-5de7b35dc56c",
   "metadata": {},
   "source": [
    "## Full Data Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "308adcf4-4904-4323-8d26-90f3b820524e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://text.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 39.0 KiB/ 39.0 KiB]                                                \n",
      "Operation completed over 1 objects/39.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(gcs_data)\n",
    "df2 = df[df[1].isin(['5','10','20','50'])]   \n",
    "df2.to_csv('text.csv', index = False,header=False)\n",
    "full_out_path=f'gs://{bucket_name}/{my_prefix}{full_dataset_name}'\n",
    "!gsutil cp 'text.csv' $full_out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb6e2b9-fb51-40b2-8bc0-d52760dfb5a4",
   "metadata": {},
   "source": [
    "## Train Data Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a060decb-0a63-41ab-9f86-deead218b816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://train_set.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 31.1 KiB/ 31.1 KiB]                                                \n",
      "Operation completed over 1 objects/31.1 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "train_data = df2.sample(frac = 0.8)\n",
    "train_data.to_csv('train_set.csv', index = False,header=False)\n",
    "train_out_path = f'gs://{bucket_name}/{my_prefix}{train_dataset_name}.csv'\n",
    "!gsutil cp 'train_set.csv' $train_out_path\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd3fb37-12cb-46fd-a921-ebfe2c226493",
   "metadata": {},
   "source": [
    "## Eval Data Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d2111c9-15d0-4f9b-8d93-b3d4fba24706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://eval_set.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  3.9 KiB/  3.9 KiB]                                                \n",
      "Operation completed over 1 objects/3.9 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe with rest of the 20% values\n",
    "non_train_data = df2.drop(train_data.index)\n",
    "eval_data = non_train_data.sample(frac = 0.5)\n",
    "eval_data.to_csv('eval_set.csv', index = False,header=False)\n",
    "eval_out_path=f'gs://{bucket_name}/{my_prefix}{eval_dataset_name}.csv'\n",
    "!gsutil cp 'eval_set.csv' $eval_out_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b896311d-c1f2-4d25-a041-b4e5c0fadf04",
   "metadata": {},
   "source": [
    "## Test Data Set Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c98bf78a-2f5b-49d9-aa47-da46c4ffdab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://test_set.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  4.0 KiB/  4.0 KiB]                                                \n",
      "Operation completed over 1 objects/4.0 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "# Creating dataframe with rest of the 20% values\n",
    "test_data = non_train_data.drop(eval_data.index)\n",
    "test_data.to_csv('test_set.csv', index = False,header=False)\n",
    "test_out_path=f'gs://{bucket_name}/{my_prefix}{test_dataset_name}.csv'\n",
    "!gsutil cp 'test_set.csv' $test_out_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a605bee-d359-4897-8d30-8ed4b170a385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
