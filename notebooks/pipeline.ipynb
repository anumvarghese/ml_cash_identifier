{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "a12c54f0-4076-4d3f-b8df-e6a94efd8581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/train.py\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import fire\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "CLASS_NAMES = ['10', '100', '20', '200', '5', '50', '500']\n",
    "train_data_path = \"gs://team4-cash-classifyimgs/euro/train_set.csv\"\n",
    "eval_data_path = \"gs://team4-cash-classify/imgs/euro/eval_set.csv\"\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "\n",
    "# Call model.predict() on a few images in the evaluation dataset\n",
    "def plot_predictions(model, filename):\n",
    "  f, ax = plt.subplots(7, 5, figsize=(25,15))\n",
    "  dataset = (tf.data.TextLineDataset(filename).\n",
    "      map(decode_csv))\n",
    "  for idx, (img, label) in enumerate(dataset.take(35)):\n",
    "    ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    label = CLASS_NAMES[label.numpy()]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "    ax[idx//5, idx%5].axis('off')\n",
    "\n",
    "def show_trained_weights(model):\n",
    "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
    "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
    "\n",
    "  f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "  for flower in range(len(CLASS_NAMES)):\n",
    "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
    "    min_wt = tf.math.reduce_min(weights).numpy()\n",
    "    max_wt = tf.math.reduce_max(weights).numpy()\n",
    "    flower_name = CLASS_NAMES[flower]\n",
    "    print(\"Scaling weights for {} in {} to {}\".format(\n",
    "        flower_name, min_wt, max_wt))\n",
    "    weights = (weights - min_wt)/(max_wt - min_wt)\n",
    "    ax[flower].imshow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, 3));\n",
    "    ax[flower].set_title(flower_name);a\n",
    "    ax[flower].axis('off')\n",
    "\n",
    "\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "  # Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # Resize the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "\n",
    "\n",
    "# the label is the index into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label\n",
    "\n",
    "# parameterize to the values in the previous cell\n",
    "def train_and_evaluate(train_data_path=f'gs://team4-cash-classify/imgs/euro/train_set.csv',\n",
    "                       eval_data_path=f'gs://team4-cash-classify/imgs/euro/eval_set.csv',\n",
    "                       CLASS_NAMES = ['10', '100', '20' ,'200', '5', '50', '500'], \n",
    "                       batch_size = 32,\n",
    "                       lrate = 0.001,\n",
    "                       l1 = 0.,\n",
    "                       l2 = 0.,\n",
    "                       num_hidden = 16):\n",
    "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "\n",
    "  train_dataset = (tf.data.TextLineDataset(\n",
    "      train_data_path).\n",
    "      map(decode_csv)).batch(batch_size)\n",
    "\n",
    "  eval_dataset = (tf.data.TextLineDataset(\n",
    "      eval_data_path).\n",
    "      map(decode_csv)).batch(32) # this doesn't matter\n",
    "\n",
    "  layers = [\n",
    "     \n",
    "      tf.keras.layers.RandomFlip(),\n",
    "      tf.keras.layers.RandomRotation(0.1),\n",
    "      hub.KerasLayer(\n",
    "          \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "\n",
    "      tf.keras.layers.Dense(num_hidden,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            activation='relu',\n",
    "                            name='dense_hidden'),\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "  ]\n",
    "\n",
    "  model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)    \n",
    "  # Save the model    \n",
    "  #model_filename = \"model.pkl\"\n",
    "  #with open(model_filename, \"wb\") as model_file:\n",
    "  #    pickle.dump(history, model_file)\n",
    "  #gcs_model_path = f\"gs://team4-cash-classify/{model_filename}\"\n",
    "  #subprocess.check_call(\n",
    "  #   [\"gsutil\", \"cp\", model_filename, gcs_model_path], stderr=sys.stdout\n",
    "  #)\n",
    "  gcs_model_path = f\"gs://team4-cash-classify/cash-classify-model-v1\"  \n",
    "  #model.save(os.getenv('AIP_MODEL_DIR'))\n",
    "  model.save(gcs_model_path)\n",
    "  \n",
    "  \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    fire.Fire(train_and_evaluate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "07ae0147-b14b-4f8d-ab45-dfc419e8f514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 17:46:50.574122: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "Epoch 1/10\n",
      "20/20 [==============================] - 60s 3s/step - loss: 1.5268 - accuracy: 0.4437 - val_loss: 1.3453 - val_accuracy: 0.5000\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 38s 2s/step - loss: 1.1507 - accuracy: 0.5641 - val_loss: 1.0321 - val_accuracy: 0.6062\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.8787 - accuracy: 0.6875 - val_loss: 0.8484 - val_accuracy: 0.6687\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 36s 2s/step - loss: 0.7154 - accuracy: 0.7406 - val_loss: 0.7464 - val_accuracy: 0.7500\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 40s 2s/step - loss: 0.5961 - accuracy: 0.7953 - val_loss: 0.6766 - val_accuracy: 0.8125\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 64s 3s/step - loss: 0.5409 - accuracy: 0.8109 - val_loss: 0.6363 - val_accuracy: 0.8313\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 58s 3s/step - loss: 0.4519 - accuracy: 0.8531 - val_loss: 0.6027 - val_accuracy: 0.8438\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 38s 2s/step - loss: 0.3809 - accuracy: 0.9000 - val_loss: 0.5591 - val_accuracy: 0.8500\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.3551 - accuracy: 0.8953 - val_loss: 0.5327 - val_accuracy: 0.8250\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 37s 2s/step - loss: 0.2993 - accuracy: 0.9219 - val_loss: 0.5095 - val_accuracy: 0.8687\n",
      "2022-04-27 17:55:50.083533: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    }
   ],
   "source": [
    "! python ../models/train.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "32dc599e-abd5-4c19-82b3-db5f1b178912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qwiklabs-gcp-00-f30184915a55\n"
     ]
    }
   ],
   "source": [
    "#Pipeline\n",
    "from google.cloud import aiplatform\n",
    "REGION = \"us-central1\"\n",
    "PROJECT_ID = !(gcloud config get-value project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "print (PROJECT_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "796bb578-329f-463d-a37b-a8057752ddee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PATH=/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/home/jupyter/.local/bin:/usr/local/cuda/bin:/opt/conda/bin:/opt/conda/condabin:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games\n"
     ]
    }
   ],
   "source": [
    "# Set `PATH` to include the directory containing KFP CLI\n",
    "PATH = %env PATH\n",
    "%env PATH=/home/jupyter/.local/bin:{PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "431d01a8-a15c-4cef-856f-1123011e82a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../models/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../models/Dockerfile\n",
    "FROM us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest\n",
    "RUN pip install -U fire cloudml-hypertune scikit-learn==0.20.4 pandas==0.24.2 fire\n",
    "WORKDIR /app\n",
    "COPY train.py .\n",
    "\n",
    "ENTRYPOINT [\"python\", \"train.py\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "58b6c91a-65d0-4a68-9708-8a02609f7453",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex:latest'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IMAGE_NAME = \"cash_classification_vertex\"\n",
    "TAG = \"latest\"\n",
    "TRAINING_CONTAINER_IMAGE_URI = f\"gcr.io/{PROJECT_ID}/{IMAGE_NAME}:{TAG}\"\n",
    "TRAINING_CONTAINER_IMAGE_URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b8c38a71-5a4a-4e2f-b080-6d305d098735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating temporary tarball archive of 7 file(s) totalling 17.5 KiB before compression.\n",
      "Uploading tarball of [../models] to [gs://qwiklabs-gcp-00-f30184915a55_cloudbuild/source/1651077807.043567-19d0bee933af4274a0499dc332fafee2.tgz]\n",
      "Created [https://cloudbuild.googleapis.com/v1/projects/qwiklabs-gcp-00-f30184915a55/locations/global/builds/85b7c0ca-b4f4-4273-87db-62aa72020b20].\n",
      "Logs are available at [https://console.cloud.google.com/cloud-build/builds/85b7c0ca-b4f4-4273-87db-62aa72020b20?project=215824651958].\n",
      "----------------------------- REMOTE BUILD OUTPUT ------------------------------\n",
      "starting build \"85b7c0ca-b4f4-4273-87db-62aa72020b20\"\n",
      "\n",
      "FETCHSOURCE\n",
      "Fetching storage object: gs://qwiklabs-gcp-00-f30184915a55_cloudbuild/source/1651077807.043567-19d0bee933af4274a0499dc332fafee2.tgz#1651077807372967\n",
      "Copying gs://qwiklabs-gcp-00-f30184915a55_cloudbuild/source/1651077807.043567-19d0bee933af4274a0499dc332fafee2.tgz#1651077807372967...\n",
      "/ [1 files][  3.5 KiB/  3.5 KiB]                                                \n",
      "Operation completed over 1 objects/3.5 KiB.\n",
      "BUILD\n",
      "Already have image (with digest): gcr.io/cloud-builders/docker\n",
      "Sending build context to Docker daemon  24.58kB\n",
      "Step 1/5 : FROM us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest\n",
      "latest: Pulling from vertex-ai/training/tf-cpu.2-7\n",
      "08c01a0ec47e: Pulling fs layer\n",
      "bd48248908bf: Pulling fs layer\n",
      "bff5af70d0ac: Pulling fs layer\n",
      "7a863f90d65e: Pulling fs layer\n",
      "4f4fb700ef54: Pulling fs layer\n",
      "a75f2205d0be: Pulling fs layer\n",
      "8f06f1106c17: Pulling fs layer\n",
      "5a8ebf5e5925: Pulling fs layer\n",
      "4441047ea5de: Pulling fs layer\n",
      "1253e9ba8ab7: Pulling fs layer\n",
      "8b11a2e9d128: Pulling fs layer\n",
      "61bd4f2d2e6f: Pulling fs layer\n",
      "f8d36dcce25d: Pulling fs layer\n",
      "f1b941ed5a20: Pulling fs layer\n",
      "9746114c8daf: Pulling fs layer\n",
      "a8c487052d75: Pulling fs layer\n",
      "6ed501e7994c: Pulling fs layer\n",
      "16e8cc467c1e: Pulling fs layer\n",
      "7cb4f7ff2cd8: Pulling fs layer\n",
      "a4d8c7d38026: Pulling fs layer\n",
      "035cebac2aa0: Pulling fs layer\n",
      "9ff76a87a8a6: Pulling fs layer\n",
      "059b9e0afcae: Pulling fs layer\n",
      "d06b9b26ee14: Pulling fs layer\n",
      "39a3fab0d295: Pulling fs layer\n",
      "f99ad5049e1d: Pulling fs layer\n",
      "7bbab75fbeb9: Pulling fs layer\n",
      "422d2142e10a: Pulling fs layer\n",
      "e2a2aa190e2a: Pulling fs layer\n",
      "8dc2da2fbf26: Pulling fs layer\n",
      "118fe2d5f420: Pulling fs layer\n",
      "8564b5338c6f: Pulling fs layer\n",
      "ebd99ebb20bf: Pulling fs layer\n",
      "caeb9ac3c484: Pulling fs layer\n",
      "7a863f90d65e: Waiting\n",
      "4f4fb700ef54: Waiting\n",
      "a75f2205d0be: Waiting\n",
      "8f06f1106c17: Waiting\n",
      "5a8ebf5e5925: Waiting\n",
      "4441047ea5de: Waiting\n",
      "1253e9ba8ab7: Waiting\n",
      "8b11a2e9d128: Waiting\n",
      "61bd4f2d2e6f: Waiting\n",
      "f8d36dcce25d: Waiting\n",
      "f1b941ed5a20: Waiting\n",
      "9746114c8daf: Waiting\n",
      "a8c487052d75: Waiting\n",
      "6ed501e7994c: Waiting\n",
      "16e8cc467c1e: Waiting\n",
      "7cb4f7ff2cd8: Waiting\n",
      "a4d8c7d38026: Waiting\n",
      "035cebac2aa0: Waiting\n",
      "9ff76a87a8a6: Waiting\n",
      "059b9e0afcae: Waiting\n",
      "d06b9b26ee14: Waiting\n",
      "39a3fab0d295: Waiting\n",
      "f99ad5049e1d: Waiting\n",
      "7bbab75fbeb9: Waiting\n",
      "422d2142e10a: Waiting\n",
      "e2a2aa190e2a: Waiting\n",
      "8dc2da2fbf26: Waiting\n",
      "118fe2d5f420: Waiting\n",
      "8564b5338c6f: Waiting\n",
      "ebd99ebb20bf: Waiting\n",
      "caeb9ac3c484: Waiting\n",
      "bd48248908bf: Verifying Checksum\n",
      "bd48248908bf: Download complete\n",
      "08c01a0ec47e: Verifying Checksum\n",
      "08c01a0ec47e: Download complete\n",
      "4f4fb700ef54: Verifying Checksum\n",
      "4f4fb700ef54: Download complete\n",
      "a75f2205d0be: Verifying Checksum\n",
      "a75f2205d0be: Download complete\n",
      "7a863f90d65e: Verifying Checksum\n",
      "7a863f90d65e: Download complete\n",
      "5a8ebf5e5925: Verifying Checksum\n",
      "5a8ebf5e5925: Download complete\n",
      "4441047ea5de: Verifying Checksum\n",
      "4441047ea5de: Download complete\n",
      "1253e9ba8ab7: Verifying Checksum\n",
      "1253e9ba8ab7: Download complete\n",
      "8f06f1106c17: Verifying Checksum\n",
      "8f06f1106c17: Download complete\n",
      "8b11a2e9d128: Verifying Checksum\n",
      "8b11a2e9d128: Download complete\n",
      "61bd4f2d2e6f: Verifying Checksum\n",
      "61bd4f2d2e6f: Download complete\n",
      "f8d36dcce25d: Verifying Checksum\n",
      "f8d36dcce25d: Download complete\n",
      "9746114c8daf: Verifying Checksum\n",
      "9746114c8daf: Download complete\n",
      "f1b941ed5a20: Verifying Checksum\n",
      "f1b941ed5a20: Download complete\n",
      "a8c487052d75: Verifying Checksum\n",
      "a8c487052d75: Download complete\n",
      "bff5af70d0ac: Download complete\n",
      "7cb4f7ff2cd8: Verifying Checksum\n",
      "7cb4f7ff2cd8: Download complete\n",
      "16e8cc467c1e: Verifying Checksum\n",
      "16e8cc467c1e: Download complete\n",
      "035cebac2aa0: Verifying Checksum\n",
      "035cebac2aa0: Download complete\n",
      "a4d8c7d38026: Verifying Checksum\n",
      "a4d8c7d38026: Download complete\n",
      "9ff76a87a8a6: Verifying Checksum\n",
      "9ff76a87a8a6: Download complete\n",
      "d06b9b26ee14: Verifying Checksum\n",
      "d06b9b26ee14: Download complete\n",
      "059b9e0afcae: Verifying Checksum\n",
      "059b9e0afcae: Download complete\n",
      "08c01a0ec47e: Pull complete\n",
      "f99ad5049e1d: Download complete\n",
      "bd48248908bf: Pull complete\n",
      "7bbab75fbeb9: Verifying Checksum\n",
      "7bbab75fbeb9: Download complete\n",
      "422d2142e10a: Verifying Checksum\n",
      "422d2142e10a: Download complete\n",
      "e2a2aa190e2a: Verifying Checksum\n",
      "e2a2aa190e2a: Download complete\n",
      "8dc2da2fbf26: Verifying Checksum\n",
      "8dc2da2fbf26: Download complete\n",
      "118fe2d5f420: Download complete\n",
      "8564b5338c6f: Verifying Checksum\n",
      "8564b5338c6f: Download complete\n",
      "ebd99ebb20bf: Verifying Checksum\n",
      "ebd99ebb20bf: Download complete\n",
      "caeb9ac3c484: Verifying Checksum\n",
      "caeb9ac3c484: Download complete\n",
      "39a3fab0d295: Verifying Checksum\n",
      "39a3fab0d295: Download complete\n",
      "6ed501e7994c: Verifying Checksum\n",
      "6ed501e7994c: Download complete\n",
      "bff5af70d0ac: Pull complete\n",
      "7a863f90d65e: Pull complete\n",
      "4f4fb700ef54: Pull complete\n",
      "a75f2205d0be: Pull complete\n",
      "8f06f1106c17: Pull complete\n",
      "5a8ebf5e5925: Pull complete\n",
      "4441047ea5de: Pull complete\n",
      "1253e9ba8ab7: Pull complete\n",
      "8b11a2e9d128: Pull complete\n",
      "61bd4f2d2e6f: Pull complete\n",
      "f8d36dcce25d: Pull complete\n",
      "f1b941ed5a20: Pull complete\n",
      "9746114c8daf: Pull complete\n",
      "a8c487052d75: Pull complete\n",
      "6ed501e7994c: Pull complete\n",
      "16e8cc467c1e: Pull complete\n",
      "7cb4f7ff2cd8: Pull complete\n",
      "a4d8c7d38026: Pull complete\n",
      "035cebac2aa0: Pull complete\n",
      "9ff76a87a8a6: Pull complete\n",
      "059b9e0afcae: Pull complete\n",
      "d06b9b26ee14: Pull complete\n",
      "39a3fab0d295: Pull complete\n",
      "f99ad5049e1d: Pull complete\n",
      "7bbab75fbeb9: Pull complete\n",
      "422d2142e10a: Pull complete\n",
      "e2a2aa190e2a: Pull complete\n",
      "8dc2da2fbf26: Pull complete\n",
      "118fe2d5f420: Pull complete\n",
      "8564b5338c6f: Pull complete\n",
      "ebd99ebb20bf: Pull complete\n",
      "caeb9ac3c484: Pull complete\n",
      "Digest: sha256:782d7dc74dc8699e686bc9e07ef92d069f8ccb8c708c47a114627dfecd5a4323\n",
      "Status: Downloaded newer image for us-docker.pkg.dev/vertex-ai/training/tf-cpu.2-7:latest\n",
      " ---> 7c90d57ab823\n",
      "Step 2/5 : RUN pip install -U fire cloudml-hypertune scikit-learn==0.20.4 pandas==0.24.2 fire\n",
      " ---> Running in 725130f5bb71\n",
      "Collecting fire\n",
      "  Downloading fire-0.4.0.tar.gz (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.7/87.7 KB 4.0 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: cloudml-hypertune in /opt/conda/lib/python3.7/site-packages (0.1.0.dev6)\n",
      "Collecting scikit-learn==0.20.4\n",
      "  Downloading scikit_learn-0.20.4-cp37-cp37m-manylinux1_x86_64.whl (5.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.4/5.4 MB 37.7 MB/s eta 0:00:00\n",
      "Collecting pandas==0.24.2\n",
      "  Downloading pandas-0.24.2-cp37-cp37m-manylinux1_x86_64.whl (10.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.1/10.1 MB 50.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=0.13.3 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from scikit-learn==0.20.4) (1.19.5)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.7/site-packages (from pandas==0.24.2) (2021.3)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from fire) (1.16.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire) (1.1.0)\n",
      "Building wheels for collected packages: fire\n",
      "  Building wheel for fire (setup.py): started\n",
      "  Building wheel for fire (setup.py): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.4.0-py2.py3-none-any.whl size=115942 sha256=36c9cfa61f95f3c19da007df0f67bda58569e8eafa93a3796d6569f66316c19b\n",
      "  Stored in directory: /root/.cache/pip/wheels/8a/67/fb/2e8a12fa16661b9d5af1f654bd199366799740a85c64981226\n",
      "Successfully built fire\n",
      "Installing collected packages: fire, scikit-learn, pandas\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.0.2\n",
      "    Uninstalling scikit-learn-1.0.2:\n",
      "      Successfully uninstalled scikit-learn-1.0.2\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "\u001b[91mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "visions 0.7.4 requires pandas>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "tfx-bsl 1.6.0 requires google-api-python-client<2,>=1.7.11, but you have google-api-python-client 2.38.0 which is incompatible.\n",
      "tfx-bsl 1.6.0 requires pandas<2,>=1.0, but you have pandas 0.24.2 which is incompatible.\n",
      "tfx-bsl 1.6.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "tensorflow-transform 1.6.0 requires pyarrow<6,>=1, but you have pyarrow 7.0.0 which is incompatible.\n",
      "statsmodels 0.13.2 requires pandas>=0.25, but you have pandas 0.24.2 which is incompatible.\n",
      "phik 0.12.0 requires pandas>=0.25.1, but you have pandas 0.24.2 which is incompatible.\n",
      "pandas-profiling 3.1.0 requires pandas!=1.0.0,!=1.0.1,!=1.0.2,!=1.1.0,>=0.25.3, but you have pandas 0.24.2 which is incompatible.\n",
      "\u001b[0mSuccessfully installed fire-0.4.0 pandas-0.24.2 scikit-learn-0.20.4\n",
      "\u001b[91mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[0mRemoving intermediate container 725130f5bb71\n",
      " ---> d65e82da35d6\n",
      "Step 3/5 : WORKDIR /app\n",
      " ---> Running in ea3e95cb28b6\n",
      "Removing intermediate container ea3e95cb28b6\n",
      " ---> ddbd3a5f5447\n",
      "Step 4/5 : COPY train.py .\n",
      " ---> 0bd1bf00f7ef\n",
      "Step 5/5 : ENTRYPOINT [\"python\", \"train.py\"]\n",
      " ---> Running in 2bba2ba83b78\n",
      "Removing intermediate container 2bba2ba83b78\n",
      " ---> 14d9be382f17\n",
      "Successfully built 14d9be382f17\n",
      "Successfully tagged gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex:latest\n",
      "PUSH\n",
      "Pushing gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex:latest\n",
      "The push refers to repository [gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex]\n",
      "849875e11f54: Preparing\n",
      "fd382a164666: Preparing\n",
      "d91506a22673: Preparing\n",
      "e42695c7b436: Preparing\n",
      "e42695c7b436: Preparing\n",
      "72f0f663075e: Preparing\n",
      "347ef3205f76: Preparing\n",
      "dc2dcd7a7fe2: Preparing\n",
      "800f5be348ca: Preparing\n",
      "800f5be348ca: Preparing\n",
      "d806f849ccb6: Preparing\n",
      "49c8b1c3d8a0: Preparing\n",
      "250b702cd2da: Preparing\n",
      "633097ab559d: Preparing\n",
      "6c82564805b7: Preparing\n",
      "3c04b6a10f71: Preparing\n",
      "daf606e74017: Preparing\n",
      "9ceb0f2763cf: Preparing\n",
      "9ceb0f2763cf: Preparing\n",
      "57f6455ec470: Preparing\n",
      "cb37f6d9ef2c: Preparing\n",
      "887d6d6b8aa4: Preparing\n",
      "fd6da66cbd6c: Preparing\n",
      "c541000c288e: Preparing\n",
      "804eb8042115: Preparing\n",
      "6535e7ceaeea: Preparing\n",
      "589d659ee3aa: Preparing\n",
      "5430153ced2f: Preparing\n",
      "8763b90e8bce: Preparing\n",
      "e686d686dc1d: Preparing\n",
      "3b98c56dcfc0: Preparing\n",
      "243bdd09476c: Preparing\n",
      "39e0384be1ed: Preparing\n",
      "ae1f0864cc76: Preparing\n",
      "f1c924e4876e: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "9aa8282950fe: Preparing\n",
      "4a1b0b19050d: Preparing\n",
      "c9ffb453bec5: Preparing\n",
      "36ffdceb4c77: Preparing\n",
      "347ef3205f76: Waiting\n",
      "dc2dcd7a7fe2: Waiting\n",
      "800f5be348ca: Waiting\n",
      "d806f849ccb6: Waiting\n",
      "49c8b1c3d8a0: Waiting\n",
      "250b702cd2da: Waiting\n",
      "633097ab559d: Waiting\n",
      "6c82564805b7: Waiting\n",
      "3c04b6a10f71: Waiting\n",
      "daf606e74017: Waiting\n",
      "9ceb0f2763cf: Waiting\n",
      "57f6455ec470: Waiting\n",
      "cb37f6d9ef2c: Waiting\n",
      "887d6d6b8aa4: Waiting\n",
      "fd6da66cbd6c: Waiting\n",
      "c541000c288e: Waiting\n",
      "804eb8042115: Waiting\n",
      "6535e7ceaeea: Waiting\n",
      "589d659ee3aa: Waiting\n",
      "5430153ced2f: Waiting\n",
      "8763b90e8bce: Waiting\n",
      "e686d686dc1d: Waiting\n",
      "3b98c56dcfc0: Waiting\n",
      "243bdd09476c: Waiting\n",
      "39e0384be1ed: Waiting\n",
      "ae1f0864cc76: Waiting\n",
      "f1c924e4876e: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "9aa8282950fe: Waiting\n",
      "4a1b0b19050d: Waiting\n",
      "c9ffb453bec5: Waiting\n",
      "36ffdceb4c77: Waiting\n",
      "e42695c7b436: Layer already exists\n",
      "72f0f663075e: Layer already exists\n",
      "347ef3205f76: Layer already exists\n",
      "dc2dcd7a7fe2: Layer already exists\n",
      "d806f849ccb6: Layer already exists\n",
      "800f5be348ca: Layer already exists\n",
      "49c8b1c3d8a0: Layer already exists\n",
      "250b702cd2da: Layer already exists\n",
      "6c82564805b7: Layer already exists\n",
      "633097ab559d: Layer already exists\n",
      "3c04b6a10f71: Layer already exists\n",
      "daf606e74017: Layer already exists\n",
      "9ceb0f2763cf: Layer already exists\n",
      "57f6455ec470: Layer already exists\n",
      "cb37f6d9ef2c: Layer already exists\n",
      "887d6d6b8aa4: Layer already exists\n",
      "fd6da66cbd6c: Layer already exists\n",
      "c541000c288e: Layer already exists\n",
      "6535e7ceaeea: Layer already exists\n",
      "804eb8042115: Layer already exists\n",
      "5430153ced2f: Layer already exists\n",
      "589d659ee3aa: Layer already exists\n",
      "e686d686dc1d: Layer already exists\n",
      "8763b90e8bce: Layer already exists\n",
      "3b98c56dcfc0: Layer already exists\n",
      "39e0384be1ed: Layer already exists\n",
      "ae1f0864cc76: Layer already exists\n",
      "f1c924e4876e: Layer already exists\n",
      "5f70bf18a086: Layer already exists\n",
      "9aa8282950fe: Layer already exists\n",
      "4a1b0b19050d: Layer already exists\n",
      "c9ffb453bec5: Layer already exists\n",
      "849875e11f54: Pushed\n",
      "36ffdceb4c77: Layer already exists\n",
      "fd382a164666: Pushed\n",
      "243bdd09476c: Pushed\n",
      "d91506a22673: Pushed\n",
      "latest: digest: sha256:7180caab14c0f2da4cde074d80ad00a40fdf633efb11dd90033e44d1d5be085b size: 8669\n",
      "DONE\n",
      "--------------------------------------------------------------------------------\n",
      "ID                                    CREATE_TIME                DURATION  SOURCE                                                                                                      IMAGES                                                                    STATUS\n",
      "85b7c0ca-b4f4-4273-87db-62aa72020b20  2022-04-27T16:43:27+00:00  3M59S     gs://qwiklabs-gcp-00-f30184915a55_cloudbuild/source/1651077807.043567-19d0bee933af4274a0499dc332fafee2.tgz  gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex (+1 more)  SUCCESS\n"
     ]
    }
   ],
   "source": [
    "!gcloud builds submit --timeout 15m --tag $TRAINING_CONTAINER_IMAGE_URI ../models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "41f3d504-1631-45e7-b897-284b59af2b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVING_CONTAINER_IMAGE_URI = (\n",
    "    \"us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-20:latest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "4b0a3e0f-ea82-494a-a8a8-b42a034acf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://qwiklabs-gcp-00-f30184915a55-kfp-artifact-store/\n"
     ]
    }
   ],
   "source": [
    "ARTIFACT_STORE = f\"gs://{PROJECT_ID}-kfp-artifact-store\"\n",
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "20204161-75d6-4264-8c85-abdf1325d1cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_ROOT=gs://team4-cash-classify/pipeline\n",
      "env: PROJECT_ID=qwiklabs-gcp-00-f30184915a55\n",
      "env: REGION=us-central1\n",
      "env: SERVING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-20:latest\n",
      "env: TRAINING_CONTAINER_IMAGE_URI=gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex:latest\n",
      "env: TRAINING_FILE_PATH=gs://team4-cash-classify/imgs/euro/train_set.csv\n",
      "env: VALIDATION_FILE_PATH=gs://team4-cash-classify/imgs/euro/eval_set.csv\n"
     ]
    }
   ],
   "source": [
    "ARTIFACT_STORE = f\"gs://team4-cash-classify\"\n",
    "PIPELINE_ROOT = f\"{ARTIFACT_STORE}/pipeline\"\n",
    "DATA_ROOT = f\"{ARTIFACT_STORE}/imgs\"\n",
    "\n",
    "TRAINING_FILE_PATH = f\"{DATA_ROOT}/euro/train_set.csv\"\n",
    "VALIDATION_FILE_PATH = f\"{DATA_ROOT}/euro/eval_set.csv\"\n",
    "REGION = \"us-central1\"\n",
    "%env PIPELINE_ROOT={PIPELINE_ROOT}\n",
    "%env PROJECT_ID={PROJECT_ID}\n",
    "%env REGION={REGION}\n",
    "%env SERVING_CONTAINER_IMAGE_URI={SERVING_CONTAINER_IMAGE_URI}\n",
    "%env TRAINING_CONTAINER_IMAGE_URI={TRAINING_CONTAINER_IMAGE_URI}\n",
    "%env TRAINING_FILE_PATH={TRAINING_FILE_PATH}\n",
    "%env VALIDATION_FILE_PATH={VALIDATION_FILE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "25cd68bc-4623-4509-b99e-f8660da17fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_JSON = \"cash_kfp_pipeline1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f9dc1d43-c07c-4452-b228-211919d473ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.cloud.aiplatform as aip\n",
    "import kfp\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from kfp.v2.dsl import component\n",
    "from kfp.v2.google import experimental\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661951ec-e1a3-4bda-99f0-d0b108b66da5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "c53853da-b7eb-4965-b7b8-909f529119be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile pipeline.py\n",
    "\n",
    "import os\n",
    "\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "from google_cloud_pipeline_components.aiplatform import (\n",
    "    EndpointCreateOp,\n",
    "    ModelDeployOp,\n",
    "    ModelUploadOp,\n",
    ")\n",
    "from google_cloud_pipeline_components.experimental import (\n",
    "    hyperparameter_tuning_job,\n",
    ")\n",
    "from google_cloud_pipeline_components.experimental.custom_job import (\n",
    "    CustomTrainingJobOp,\n",
    ")\n",
    "from kfp.v2 import dsl\n",
    "\n",
    "PIPELINE_ROOT = os.getenv(\"PIPELINE_ROOT\")\n",
    "PROJECT_ID = os.getenv(\"PROJECT_ID\")\n",
    "REGION = os.getenv(\"REGION\")\n",
    "\n",
    "TRAINING_CONTAINER_IMAGE_URI = os.getenv(\"TRAINING_CONTAINER_IMAGE_URI\")\n",
    "SERVING_CONTAINER_IMAGE_URI = os.getenv(\"SERVING_CONTAINER_IMAGE_URI\")\n",
    "SERVING_MACHINE_TYPE = os.getenv(\"SERVING_MACHINE_TYPE\", \"n1-standard-16\")\n",
    "\n",
    "TRAINING_FILE_PATH = os.getenv(\"TRAINING_FILE_PATH\")\n",
    "VALIDATION_FILE_PATH = os.getenv(\"VALIDATION_FILE_PATH\")\n",
    "\n",
    "MAX_TRIAL_COUNT = int(os.getenv(\"MAX_TRIAL_COUNT\", \"5\"))\n",
    "PARALLEL_TRIAL_COUNT = int(os.getenv(\"PARALLEL_TRIAL_COUNT\", \"5\"))\n",
    "THRESHOLD = float(os.getenv(\"THRESHOLD\", \"0.6\"))\n",
    "\n",
    "PIPELINE_NAME = os.getenv(\"PIPELINE_NAME\", \"cash-classification\")\n",
    "BASE_OUTPUT_DIR = os.getenv(\"BASE_OUTPUT_DIR\", PIPELINE_ROOT)\n",
    "MODEL_DISPLAY_NAME = os.getenv(\"MODEL_DISPLAY_NAME\", PIPELINE_NAME)\n",
    "\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name=f\"{PIPELINE_NAME}-kfp-pipeline\",\n",
    "    description=\"Kubeflow pipeline that tunes, trains, and deploys on Vertex\",\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "def create_pipeline():\n",
    "\n",
    "    worker_pool_specs = [\n",
    "        {\n",
    "            \"machine_spec\": {\n",
    "                \"machine_type\": \"n1-standard-4\",\n",
    "                \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "                \"accelerator_count\": 1,\n",
    "            },\n",
    "            \"replica_count\": 1,\n",
    "            \"container_spec\": {\n",
    "                \"image_uri\": TRAINING_CONTAINER_IMAGE_URI,\n",
    "                \"args\": [\n",
    "                    f\"--train_data_path={TRAINING_FILE_PATH}\",\n",
    "                    f\"--eval_data_path={VALIDATION_FILE_PATH}\",\n",
    "                ],\n",
    "            },\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    metric_spec = hyperparameter_tuning_job.serialize_metrics(\n",
    "        {\"accuracy\": \"maximize\"}\n",
    "    )\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # Construct new worker_pool_specs and\n",
    "    # train new model based on best hyperparameters\n",
    "\n",
    "    training_task = CustomTrainingJobOp(\n",
    "        project=PROJECT_ID,\n",
    "        location=REGION,\n",
    "        display_name=f\"{PIPELINE_NAME}-kfp-training-job\",\n",
    "        worker_pool_specs= \n",
    "        [\n",
    "            {\n",
    "                \"machine_spec\": {\"machine_type\": \"n1-standard-4\"},\n",
    "                \"replica_count\": 1,\n",
    "                \"container_spec\": {\n",
    "                    \"image_uri\": TRAINING_CONTAINER_IMAGE_URI,\n",
    "                    \"args\": [\n",
    "                        f\"--train_data_path={TRAINING_FILE_PATH}\",\n",
    "                        f\"--eval_data_path={VALIDATION_FILE_PATH}\",\n",
    "                    ],\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "        base_output_directory=BASE_OUTPUT_DIR,\n",
    "    )\n",
    "\n",
    "    model_upload_task = ModelUploadOp(\n",
    "        project=PROJECT_ID,\n",
    "        display_name=f\"{PIPELINE_NAME}-kfp-model-upload-job\",\n",
    "        artifact_uri=f\"{BASE_OUTPUT_DIR}/model\",\n",
    "        serving_container_image_uri=SERVING_CONTAINER_IMAGE_URI,\n",
    "    )\n",
    "    model_upload_task.after(training_task)\n",
    "\n",
    "    endpoint_create_task = EndpointCreateOp(\n",
    "        project=PROJECT_ID,\n",
    "        display_name=f\"{PIPELINE_NAME}-kfp-create-endpoint-job\",\n",
    "    )\n",
    "    endpoint_create_task.after(model_upload_task)\n",
    "\n",
    "    model_deploy_op = ModelDeployOp(  # pylint: disable=unused-variable\n",
    "        model=model_upload_task.outputs[\"model\"],\n",
    "        endpoint=endpoint_create_task.outputs[\"endpoint\"],\n",
    "        deployed_model_display_name=MODEL_DISPLAY_NAME,\n",
    "        dedicated_resources_machine_type=SERVING_MACHINE_TYPE,\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "9c8a3ea2-86c7-4300-8da1-b6b5402db97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://team4-cash-classify/\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls | grep ^{ARTIFACT_STORE}/$ || gsutil mb -l {REGION} {ARTIFACT_STORE}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "3d4578a4-630d-47bc-b3dd-78f9c212c636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PIPELINE_ROOT=gs://team4-cash-classify/pipeline\n",
      "env: PROJECT_ID=qwiklabs-gcp-00-f30184915a55\n",
      "env: REGION=us-central1\n",
      "env: SERVING_CONTAINER_IMAGE_URI=us-docker.pkg.dev/vertex-ai/prediction/sklearn-cpu.0-20:latest\n",
      "env: TRAINING_CONTAINER_IMAGE_URI=gcr.io/qwiklabs-gcp-00-f30184915a55/cash_classification_vertex:latest\n",
      "env: TRAINING_FILE_PATH=gs://team4-cash-classify/imgs/euro/train_set.csv\n",
      "env: VALIDATION_FILE_PATH=gs://team4-cash-classify/imgs/euro/eval_set.csv\n",
      "env: BASE_OUTPUT_DIR=gs://team4-cash-classify/models/20220427164747\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "from google.cloud import aiplatform\n",
    "\n",
    "#ARTIFACT_STORE = f\"gs://{PROJECT_ID}-kfp-artifact-store\"\n",
    "ARTIFACT_STORE =  f\"gs://team4-cash-classify\"\n",
    "PIPELINE_ROOT = f\"{ARTIFACT_STORE}/pipeline\"\n",
    "DATA_ROOT = f\"{ARTIFACT_STORE}/imgs\"\n",
    "\n",
    "TRAINING_FILE_PATH = f\"{DATA_ROOT}/euro/train_set.csv\"\n",
    "VALIDATION_FILE_PATH = f\"{DATA_ROOT}/euro/eval_set.csv\"\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BASE_OUTPUT_DIR = f\"{ARTIFACT_STORE}/models/{TIMESTAMP}\"\n",
    "\n",
    "%env PIPELINE_ROOT={PIPELINE_ROOT}\n",
    "%env PROJECT_ID={PROJECT_ID}\n",
    "%env REGION={REGION}\n",
    "%env SERVING_CONTAINER_IMAGE_URI={SERVING_CONTAINER_IMAGE_URI}\n",
    "%env TRAINING_CONTAINER_IMAGE_URI={TRAINING_CONTAINER_IMAGE_URI}\n",
    "%env TRAINING_FILE_PATH={TRAINING_FILE_PATH}\n",
    "%env VALIDATION_FILE_PATH={VALIDATION_FILE_PATH}\n",
    "%env BASE_OUTPUT_DIR={BASE_OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c09fa260-76fa-44a5-8212-a6fb4f373fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_JSON = \"cash_kfp_pipeline1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "929f6557-d373-4abd-934f-9bfdb076cce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kfp in /opt/conda/lib/python3.7/site-packages (1.8.12)\n",
      "Requirement already satisfied: kubernetes<19,>=8.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (18.20.0)\n",
      "Requirement already satisfied: uritemplate<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.0.1)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions<4,>=3.7.4 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.10.0.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.3.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.1)\n",
      "Requirement already satisfied: cloudpickle<3,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (2.0.0)\n",
      "Requirement already satisfied: requests-toolbelt<1,>=0.8.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.9.1)\n",
      "Requirement already satisfied: PyYAML<6,>=5.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (5.4.1)\n",
      "Requirement already satisfied: kfp-server-api<2.0.0,>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.8.1)\n",
      "Requirement already satisfied: protobuf<4,>=3.13.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.19.4)\n",
      "Requirement already satisfied: pydantic<2,>=1.8.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.9.0)\n",
      "Requirement already satisfied: absl-py<2,>=0.9 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.0.0)\n",
      "Requirement already satisfied: google-cloud-storage<2,>=1.20.0 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.44.0)\n",
      "Requirement already satisfied: Deprecated<2,>=1.2.7 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.2.13)\n",
      "Requirement already satisfied: google-auth<2,>=1.6.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.35.0)\n",
      "Requirement already satisfied: kfp-pipeline-spec<0.2.0,>=0.1.14 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.14)\n",
      "Requirement already satisfied: strip-hints<1,>=0.1.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.1.10)\n",
      "Requirement already satisfied: docstring-parser<1,>=0.7.3 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.14)\n",
      "Requirement already satisfied: jsonschema<4,>=3.0.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (3.2.0)\n",
      "Requirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.8.9)\n",
      "Requirement already satisfied: fire<1,>=0.3.1 in /opt/conda/lib/python3.7/site-packages (from kfp) (0.4.0)\n",
      "Requirement already satisfied: click<9,>=7.1.2 in /opt/conda/lib/python3.7/site-packages (from kfp) (8.0.4)\n",
      "Requirement already satisfied: google-api-python-client<2,>=1.7.8 in /opt/conda/lib/python3.7/site-packages (from kfp) (1.12.11)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from absl-py<2,>=0.9->kfp) (1.16.0)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from click<9,>=7.1.2->kfp) (4.11.3)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.7/site-packages (from Deprecated<2,>=1.2.7->kfp) (1.14.0)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.7/site-packages (from fire<1,>=0.3.1->kfp) (1.1.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (1.54.0)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /opt/conda/lib/python3.7/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.27.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.20.4)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /opt/conda/lib/python3.7/site-packages (from google-api-python-client<2,>=1.7.8->kfp) (0.1.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (4.8)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (59.8.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<2,>=1.6.1->kfp) (0.2.7)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=1.3.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.3.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0dev,>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from google-cloud-storage<2,>=1.20.0->kfp) (2.2.3)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (0.18.1)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.7/site-packages (from jsonschema<4,>=3.0.1->kfp) (21.4.0)\n",
      "Requirement already satisfied: python-dateutil in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2.8.2)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (2021.10.8)\n",
      "Requirement already satisfied: urllib3>=1.15 in /opt/conda/lib/python3.7/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp) (1.26.8)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /opt/conda/lib/python3.7/site-packages (from kubernetes<19,>=8.0.0->kfp) (1.3.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.7/site-packages (from strip-hints<1,>=0.1.8->kfp) (0.37.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /opt/conda/lib/python3.7/site-packages (from google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.7/site-packages (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp) (3.0.7)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.1->kfp) (0.4.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3.0.0dev,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp) (3.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->click<9,>=7.1.2->kfp) (3.7.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib->kubernetes<19,>=8.0.0->kfp) (3.2.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (1.15.0)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.7/site-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0->google-resumable-media<3.0dev,>=1.3.0->google-cloud-storage<2,>=1.20.0->kfp) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install kfp --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "cec6d876-d1bf-40ff-a17d-4eca9a07c6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/kfp/v2/compiler/compiler.py:1281: FutureWarning: APIs imported from the v1 namespace (e.g. kfp.dsl, kfp.components, etc) will not be supported by the v2 compiler since v2.0.0\n",
      "  category=FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "!dsl-compile-v2 --py pipeline.py --output $PIPELINE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "b9a19dd1-2ee1-4f54-a86d-7dde4a5a8291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/cash-classification-kfp-pipeline-20220427164757?project=215824651958\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-classification-kfp-pipeline-20220427164757 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [custom-training-job].; Job (project_id = qwiklabs-gcp-00-f30184915a55, job_id = 7610258736535306240) is failed due to the above error.; Failed to handle the job: {project_number = 215824651958, job_id = 7610258736535306240}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25288/3693994385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     def submit(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [custom-training-job].; Job (project_id = qwiklabs-gcp-00-f30184915a55, job_id = 7610258736535306240) is failed due to the above error.; Failed to handle the job: {project_number = 215824651958, job_id = 7610258736535306240}\"\n"
     ]
    }
   ],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)\n",
    "\n",
    "pipeline = aiplatform.PipelineJob(\n",
    "    display_name=\"cash_kfp_pipeline\",\n",
    "    template_path=PIPELINE_JSON,\n",
    "    enable_caching=True,\n",
    ")\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f86cf1-f983-40be-adab-ac4b4356e76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=create_pipeline,\n",
    "    package_path=\"tabular regression_pipeline.json\".replace(\" \", \"_\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ec27c092-01bc-4101-b410-e1306bc19305",
   "metadata": {},
   "outputs": [],
   "source": [
    "@component\n",
    "def print_op(input1: str):\n",
    "    print(\"training task: {}\".format(input1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f54c68-3c57-4999-ba5c-3b259dbd65c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "delete_dataset = True\n",
    "delete_pipeline = True\n",
    "delete_model = True\n",
    "delete_endpoint = True\n",
    "delete_batchjob = True\n",
    "delete_customjob = True\n",
    "delete_hptjob = True\n",
    "delete_bucket = True\n",
    "\n",
    "try:\n",
    "    if delete_model and \"DISPLAY_NAME\" in globals():\n",
    "        models = aip.Model.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "        )\n",
    "        model = models[0]\n",
    "        aip.Model.delete(model)\n",
    "        print(\"Deleted model:\", model)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "try:\n",
    "    if delete_endpoint and \"DISPLAY_NAME\" in globals():\n",
    "        endpoints = aip.Endpoint.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}_endpoint\", order_by=\"create_time\"\n",
    "        )\n",
    "        endpoint = endpoints[0]\n",
    "        endpoint.undeploy_all()\n",
    "        aip.Endpoint.delete(endpoint.resource_name)\n",
    "        print(\"Deleted endpoint:\", endpoint)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_dataset and \"DISPLAY_NAME\" in globals():\n",
    "    if \"tabular\" == \"tabular\":\n",
    "        try:\n",
    "            datasets = aip.TabularDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.TabularDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"tabular\" == \"image\":\n",
    "        try:\n",
    "            datasets = aip.ImageDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.ImageDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"tabular\" == \"text\":\n",
    "        try:\n",
    "            datasets = aip.TextDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.TextDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "    if \"tabular\" == \"video\":\n",
    "        try:\n",
    "            datasets = aip.VideoDataset.list(\n",
    "                filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "            )\n",
    "            dataset = datasets[0]\n",
    "            aip.VideoDataset.delete(dataset.resource_name)\n",
    "            print(\"Deleted dataset:\", dataset)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "\n",
    "try:\n",
    "    if delete_pipeline and \"DISPLAY_NAME\" in globals():\n",
    "        pipelines = aip.PipelineJob.list(\n",
    "            filter=f\"display_name={DISPLAY_NAME}\", order_by=\"create_time\"\n",
    "        )\n",
    "        pipeline = pipelines[0]\n",
    "        aip.PipelineJob.delete(pipeline.resource_name)\n",
    "        print(\"Deleted pipeline:\", pipeline)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "if delete_bucket and \"BUCKET_NAME\" in globals():\n",
    "    ! gsutil rm -r $BUCKET_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "63b495d0-76ea-4eea-bd03-9f11803c0eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[] gs://team4-cash-classify/pipeline/20220427164747 cash_train_deploy20220427164747\n"
     ]
    }
   ],
   "source": [
    "hp_dict: str = '{\"num_hidden_layers\": 3, \"hidden_size\": 32, \"learning_rate\": 0.01, \"epochs\": 1, \"steps_per_epoch\": -1}'\n",
    "data_dir: str = \"gs://aju-dev-demos-codelabs/bikes_weather/\"\n",
    "train_data_path=f'gs://team4-cash-classify/imgs/euro/train_set.csv'\n",
    "eval_data_path=f'gs://team4-cash-classify/imgs/euro/eval_set.csv',\n",
    "TRAINER_ARGS = []\n",
    "\n",
    "# create working dir to pass to job spec\n",
    "WORKING_DIR = f\"{PIPELINE_ROOT}/{TIMESTAMP}\"\n",
    "\n",
    "MODEL_DISPLAY_NAME = f\"cash_train_deploy{TIMESTAMP}\"\n",
    "print(TRAINER_ARGS, WORKING_DIR, MODEL_DISPLAY_NAME)\n",
    "\n",
    "\n",
    "@kfp.dsl.pipeline(name=\"cash-train-endpoint-deploy\" + TIMESTAMP)\n",
    "def pipeline(\n",
    "    project: str = PROJECT_ID,\n",
    "    model_display_name: str = MODEL_DISPLAY_NAME,\n",
    "    serving_container_image_uri: str = \"us-docker.pkg.dev/cloud-aiplatform/prediction/tf2-cpu.2-3:latest\",\n",
    "):\n",
    "\n",
    "    train_task = print_op(\"model training\")\n",
    "    experimental.run_as_aiplatform_custom_job(\n",
    "        train_task,\n",
    "        worker_pool_specs=[\n",
    "            {\n",
    "                \"containerSpec\": {\n",
    "                    \"args\": TRAINER_ARGS,\n",
    "                    \"env\": [{\"name\": \"AIP_MODEL_DIR\", \"value\": WORKING_DIR}],\n",
    "                    \"imageUri\": TRAINING_CONTAINER_IMAGE_URI,\n",
    "                },\n",
    "                \"replicaCount\": \"1\",\n",
    "                \"machineSpec\": {\n",
    "                    \"machineType\": \"n1-standard-16\",\n",
    "                    \"accelerator_type\": aip.gapic.AcceleratorType.NVIDIA_TESLA_K80,\n",
    "                    \"accelerator_count\": 2,\n",
    "                },\n",
    "            }\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    model_upload_op = gcc_aip.ModelUploadOp(\n",
    "        project=project,\n",
    "        display_name=model_display_name,\n",
    "        artifact_uri=WORKING_DIR,\n",
    "        serving_container_image_uri=serving_container_image_uri,\n",
    "        # serving_container_environment_variables={\"NOT_USED\": \"NO_VALUE\"},\n",
    "    )\n",
    "    model_upload_op.after(train_task)\n",
    "\n",
    "    endpoint_create_op = gcc_aip.EndpointCreateOp(\n",
    "        project=project,\n",
    "        display_name=\"pipelines-created-endpoint\",\n",
    "    )\n",
    "\n",
    "    gcc_aip.ModelDeployOp(\n",
    "        endpoint=endpoint_create_op.outputs[\"endpoint\"],\n",
    "        model=model_upload_op.outputs[\"model\"],\n",
    "        deployed_model_display_name=model_display_name,\n",
    "        dedicated_resources_machine_type=\"n1-standard-16\",\n",
    "        dedicated_resources_min_replica_count=1,\n",
    "        dedicated_resources_max_replica_count=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "097f70d3-1d72-41a6-b50c-3b505e7d8e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfp.v2 import compiler  # noqa: F811\n",
    "\n",
    "compiler.Compiler().compile(\n",
    "    pipeline_func=pipeline,\n",
    "    package_path=\"tabular regression_pipeline.json\".replace(\" \", \"_\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "3bcf3155-78b0-4b93-88b5-2ea5831f3068",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.pipeline_jobs:Creating PipelineJob\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob created. Resource name: projects/215824651958/locations/us-central1/pipelineJobs/cash-train-endpoint-deploy20220427164747-20220427170720\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:To use this PipelineJob in another session:\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:pipeline_job = aiplatform.PipelineJob.get('projects/215824651958/locations/us-central1/pipelineJobs/cash-train-endpoint-deploy20220427164747-20220427170720')\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:View Pipeline Job:\n",
      "https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/cash-train-endpoint-deploy20220427164747-20220427170720?project=215824651958\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-train-endpoint-deploy20220427164747-20220427170720 current state:\n",
      "PipelineState.PIPELINE_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-train-endpoint-deploy20220427164747-20220427170720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-train-endpoint-deploy20220427164747-20220427170720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.pipeline_jobs:PipelineJob projects/215824651958/locations/us-central1/pipelineJobs/cash-train-endpoint-deploy20220427164747-20220427170720 current state:\n",
      "PipelineState.PIPELINE_STATE_RUNNING\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [print-op].; Job (project_id = qwiklabs-gcp-00-f30184915a55, job_id = 4465620296723857408) is failed due to the above error.; Failed to handle the job: {project_number = 215824651958, job_id = 4465620296723857408}\"\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_25288/4222553949.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' rm tabular_regression_pipeline.json'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    728\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m                     \u001b[0mVertexAiResourceNounWithFutureManager\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;31m# callbacks to call within the Future (in same Thread)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, service_account, network, sync)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mservice_account\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_block_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m     def submit(\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/google/cloud/aiplatform/pipeline_jobs.py\u001b[0m in \u001b[0;36m_block_until_complete\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m         \u001b[0;31m# JOB_STATE_FAILED or JOB_STATE_CANCELLED.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_PIPELINE_ERROR_STATES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Job failed with:\\n%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m             \u001b[0m_LOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_action_completed_against_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"completed\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Job failed with:\ncode: 9\nmessage: \"The DAG failed because some tasks failed. The failed tasks are: [print-op].; Job (project_id = qwiklabs-gcp-00-f30184915a55, job_id = 4465620296723857408) is failed due to the above error.; Failed to handle the job: {project_number = 215824651958, job_id = 4465620296723857408}\"\n"
     ]
    }
   ],
   "source": [
    "DISPLAY_NAME = \"bikes_weather_\" + TIMESTAMP\n",
    "\n",
    "job = aip.PipelineJob(\n",
    "    display_name=DISPLAY_NAME,\n",
    "    template_path=\"tabular regression_pipeline.json\".replace(\" \", \"_\"),\n",
    "    pipeline_root=PIPELINE_ROOT,\n",
    ")\n",
    "\n",
    "job.run()\n",
    "\n",
    "! rm tabular_regression_pipeline.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "c4da52c5-538b-4c64-95c5-9abfbe35a9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "\n",
    "# Call model.predict() on a few images in the evaluation dataset\n",
    "def plot_predictions(model, filename):\n",
    "  f, ax = plt.subplots(7, 5, figsize=(25,15))\n",
    "  dataset = (tf.data.TextLineDataset(filename).\n",
    "      map(decode_csv))\n",
    "  for idx, (img, label) in enumerate(dataset.take(35)):\n",
    "    ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    label = CLASS_NAMES[label.numpy()]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "    ax[idx//5, idx%5].axis('off')\n",
    "\n",
    "def show_trained_weights(model):\n",
    "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
    "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
    "\n",
    "  f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "  for flower in range(len(CLASS_NAMES)):\n",
    "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
    "    min_wt = tf.math.reduce_min(weights).numpy()\n",
    "    max_wt = tf.math.reduce_max(weights).numpy()\n",
    "    flower_name = CLASS_NAMES[flower]\n",
    "    print(\"Scaling weights for {} in {} to {}\".format(\n",
    "        flower_name, min_wt, max_wt))\n",
    "    weights = (weights - min_wt)/(max_wt - min_wt)\n",
    "    ax[flower].imshow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, 3));\n",
    "    ax[flower].set_title(flower_name);a\n",
    "    ax[flower].axis('off')\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "  # Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # Resize the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "\n",
    "\n",
    "# the label is the index into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "7ddcc8c2-1e78-4832-9a05-77e800e412c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "CLASS_NAMES = ['10', '100', '20', '200', '5', '50', '500']\n",
    "train_data_path = \"gs://team4-cash-classify/imgs/euro/train_set.csv\"\n",
    "eval_data_path = \"gs://team4-cash-classify/imgs/euro/eval_set.csv\"\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "# parameterize to the values in the previous cell\n",
    "def create_model(batch_size = 32,\n",
    "                       lrate = 0.001,\n",
    "                       l1 = 0.,\n",
    "                       l2 = 0.,\n",
    "                       num_hidden = 16):\n",
    "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "\n",
    "\n",
    "\n",
    "  # train_dataset2 = tf.keras.layers.RandomFlip()(train_dataset)\n",
    "  #eval_dataset2 = tf.keras.layers.RandomFlip()(eval_dataset2)\n",
    "\n",
    "  layers = [\n",
    "     \n",
    "      tf.keras.layers.RandomFlip(),\n",
    "      tf.keras.layers.RandomRotation(0.1),\n",
    "      hub.KerasLayer(\n",
    "          \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "\n",
    "      tf.keras.layers.Dense(num_hidden,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            activation='relu',\n",
    "                            name='dense_hidden'),\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "  ]\n",
    "\n",
    "  model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  # model.build()\n",
    "  # print(model.summary())\n",
    "  #history = model.fit(train_dataset, validation_data=eval_dataset, epochs=2)\n",
    "  #training_plot(['loss', 'accuracy'], history)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "024c1590-ba06-41b5-888e-8d21341e6656",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model,epochs,batch_size=32):\n",
    "  train_dataset = (tf.data.TextLineDataset(\n",
    "      train_data_path).\n",
    "      map(decode_csv)).batch(batch_size)\n",
    "\n",
    "  eval_dataset = (tf.data.TextLineDataset(\n",
    "      eval_data_path).\n",
    "      map(decode_csv)).batch(32) # this doesn't matter\n",
    "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=epochs)\n",
    "  training_plot(['loss', 'accuracy'], history)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "58b0f817-25cf-4a3c-92f1-e872ec26d4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa95dc-66e4-4c31-ae5b-5a57f7429762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "20/20 [==============================] - 76s 3s/step - loss: 1.5351 - accuracy: 0.4125 - val_loss: 1.3638 - val_accuracy: 0.4688\n",
      "Epoch 2/5\n",
      "20/20 [==============================] - 45s 2s/step - loss: 1.1947 - accuracy: 0.5422 - val_loss: 1.1061 - val_accuracy: 0.5562\n",
      "Epoch 3/5\n",
      "20/20 [==============================] - 45s 2s/step - loss: 1.0031 - accuracy: 0.6469 - val_loss: 0.9449 - val_accuracy: 0.6438\n",
      "Epoch 4/5\n"
     ]
    }
   ],
   "source": [
    "model = train_and_evaluate(model,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "abd646da-e9cd-40d9-bf4c-3b4db81ed398",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import os\n",
    "import fire\n",
    "\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "CLASS_NAMES = ['10', '100', '20', '200', '5', '50', '500']\n",
    "train_data_path = \"gs://team4-cash-classifyimgs/euro/train_set.csv\"\n",
    "eval_data_path = \"gs://team4-cash-classify/imgs/euro/eval_set.csv\"\n",
    "\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "\n",
    "# Call model.predict() on a few images in the evaluation dataset\n",
    "def plot_predictions(model, filename):\n",
    "  f, ax = plt.subplots(7, 5, figsize=(25,15))\n",
    "  dataset = (tf.data.TextLineDataset(filename).\n",
    "      map(decode_csv))\n",
    "  for idx, (img, label) in enumerate(dataset.take(35)):\n",
    "    ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    label = CLASS_NAMES[label.numpy()]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "    ax[idx//5, idx%5].axis('off')\n",
    "\n",
    "def show_trained_weights(model):\n",
    "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
    "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
    "\n",
    "  f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "  for flower in range(len(CLASS_NAMES)):\n",
    "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
    "    min_wt = tf.math.reduce_min(weights).numpy()\n",
    "    max_wt = tf.math.reduce_max(weights).numpy()\n",
    "    flower_name = CLASS_NAMES[flower]\n",
    "    print(\"Scaling weights for {} in {} to {}\".format(\n",
    "        flower_name, min_wt, max_wt))\n",
    "    weights = (weights - min_wt)/(max_wt - min_wt)\n",
    "    ax[flower].imshow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, 3));\n",
    "    ax[flower].set_title(flower_name);a\n",
    "    ax[flower].axis('off')\n",
    "\n",
    "\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "  # Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # Resize the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "\n",
    "\n",
    "# the label is the index into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label\n",
    "\n",
    "# parameterize to the values in the previous cell\n",
    "def train_and_evaluate(train_data_path=f'gs://team4-cash-classify/imgs/euro/train_set.csv',\n",
    "                       eval_data_path=f'gs://team4-cash-classify/imgs/euro/eval_set.csv',\n",
    "                       CLASS_NAMES = ['10', '100', '20' ,'200', '5', '50', '500'], \n",
    "                       batch_size = 32,\n",
    "                       lrate = 0.001,\n",
    "                       l1 = 0.,\n",
    "                       l2 = 0.,\n",
    "                       num_hidden = 16):\n",
    "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "\n",
    "  train_dataset = (tf.data.TextLineDataset(\n",
    "      train_data_path).\n",
    "      map(decode_csv)).batch(batch_size)\n",
    "\n",
    "  eval_dataset = (tf.data.TextLineDataset(\n",
    "      eval_data_path).\n",
    "      map(decode_csv)).batch(32) # this doesn't matter\n",
    "\n",
    "  layers = [\n",
    "     \n",
    "      tf.keras.layers.RandomFlip(),\n",
    "      tf.keras.layers.RandomRotation(0.1),\n",
    "      hub.KerasLayer(\n",
    "          \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "\n",
    "      tf.keras.layers.Dense(num_hidden,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            activation='relu',\n",
    "                            name='dense_hidden'),\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "  ]\n",
    "\n",
    "  model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  \n",
    "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=10)    \n",
    "  # Save the model    \n",
    "  #model_filename = \"model.pkl\"\n",
    "  #with open(model_filename, \"wb\") as model_file:\n",
    "  #    pickle.dump(history, model_file)\n",
    "  #gcs_model_path = f\"gs://team4-cash-classify/{model_filename}\"\n",
    "  #subprocess.check_call(\n",
    "  #   [\"gsutil\", \"cp\", model_filename, gcs_model_path], stderr=sys.stdout\n",
    "  #)\n",
    "  gcs_model_path = f\"gs://team4-cash-classify/cash-classify-model-v1\"  \n",
    "  #model.save(os.getenv('AIP_MODEL_DIR'))\n",
    "  #model.save(gcs_model_path)\n",
    "  return model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "57dd86d1-bfa9-48ad-aec3-9352f007bb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 56s 3s/step - loss: 1.6547 - accuracy: 0.4313 - val_loss: 1.4542 - val_accuracy: 0.4563\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 43s 2s/step - loss: 1.3230 - accuracy: 0.5203 - val_loss: 1.2215 - val_accuracy: 0.5188\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 43s 2s/step - loss: 1.1575 - accuracy: 0.5891 - val_loss: 1.1020 - val_accuracy: 0.5625\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 1.0083 - accuracy: 0.6578 - val_loss: 0.9862 - val_accuracy: 0.6438\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 42s 2s/step - loss: 0.8475 - accuracy: 0.6984 - val_loss: 0.8675 - val_accuracy: 0.7000\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.7480 - accuracy: 0.7469 - val_loss: 0.8175 - val_accuracy: 0.7063\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.6839 - accuracy: 0.7484 - val_loss: 0.7573 - val_accuracy: 0.7188\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 43s 2s/step - loss: 0.6051 - accuracy: 0.7875 - val_loss: 0.7260 - val_accuracy: 0.7125\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 48s 2s/step - loss: 0.5674 - accuracy: 0.8266 - val_loss: 0.6971 - val_accuracy: 0.7312\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 41s 2s/step - loss: 0.5244 - accuracy: 0.8313 - val_loss: 0.6645 - val_accuracy: 0.7563\n"
     ]
    }
   ],
   "source": [
    "model=train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "87cb7ba0-b2fa-4ba0-93e4-96b3e94d4038",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-27 22:04:25.782755: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: gs://team4-cash-classify/cmodelv1/assets\n"
     ]
    }
   ],
   "source": [
    "# Save Model Iteration\n",
    "model.save(f'gs://team4-cash-classify/cmodelv1')\n",
    "BUCKET = \"team4-cash-classify\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475c583a-3225-43e9-82ca-60d66a14abdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"EXPORT_PATH\"] = f'gs://team4-cash-classify/cmodelv1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "d41dd0d0-acac-49c5-9783-e75b9e969dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://team4-cash-classify/cmodelv1\n",
      "MODEL_DISPLAYNAME=cash_clasify_20220427_221643\n",
      "MODEL_RESOURCENAME=projects/215824651958/locations/us-central1/models/3603394273338195968\n",
      "MODEL_ID=3603394273338195968\n",
      "ENDPOINT_DISPLAYNAME=cash_clasify_endpoint_20220427_221643\n",
      "ENDPOINT_RESOURCENAME=projects/215824651958/locations/us-central1/endpoints/4344539877249908736\n",
      "ENDPOINT_ID=4344539877249908736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [8806523607984373760]...\n",
      "...................done.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [7842753287727087616]...\n",
      "......done.\n",
      "Created Vertex AI endpoint: projects/215824651958/locations/us-central1/endpoints/4344539877249908736.\n",
      "Using endpoint [https://us-central1-aiplatform.googleapis.com/]\n",
      "Waiting for operation [6225961021501079552]...\n",
      ".....................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................done.\n",
      "Deployed a model to the endpoint 4344539877249908736. Id of the deployed model: 5983515890077925376.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "TIMESTAMP=$(date -u +%Y%m%d_%H%M%S)\n",
    "MODEL_DISPLAYNAME=cash_clasify_$TIMESTAMP\n",
    "ENDPOINT_DISPLAYNAME=cash_clasify_endpoint_$TIMESTAMP\n",
    "IMAGE_URI=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-5:latest\"\n",
    "ARTIFACT_DIRECTORY='gs://team4-cash-classify/cmodelv1'\n",
    "echo $ARTIFACT_DIRECTORY\n",
    "\n",
    "#gsutil cp -r ${EXPORT_PATH}/* ${ARTIFACT_DIRECTORY}\n",
    "\n",
    "# Model\n",
    "MODEL_RESOURCENAME=$(gcloud ai models upload \\\n",
    "    --region=$REGION \\\n",
    "    --display-name=$MODEL_DISPLAYNAME \\\n",
    "    --container-image-uri=$IMAGE_URI \\\n",
    "    --artifact-uri=$ARTIFACT_DIRECTORY \\\n",
    "    --format=\"value(model)\")\n",
    "\n",
    "MODEL_ID=$(echo $MODEL_RESOURCENAME | cut -d\"/\" -f6)\n",
    "\n",
    "echo \"MODEL_DISPLAYNAME=${MODEL_DISPLAYNAME}\"\n",
    "echo \"MODEL_RESOURCENAME=${MODEL_RESOURCENAME}\"\n",
    "echo \"MODEL_ID=${MODEL_ID}\"\n",
    "\n",
    "# Endpoint\n",
    "ENDPOINT_RESOURCENAME=$(gcloud ai endpoints create \\\n",
    "  --region=$REGION \\\n",
    "  --display-name=$ENDPOINT_DISPLAYNAME \\\n",
    "  --format=\"value(name)\")\n",
    "\n",
    "ENDPOINT_ID=$(echo $ENDPOINT_RESOURCENAME | cut -d\"/\" -f6)\n",
    "\n",
    "echo \"ENDPOINT_DISPLAYNAME=${ENDPOINT_DISPLAYNAME}\"\n",
    "echo \"ENDPOINT_RESOURCENAME=${ENDPOINT_RESOURCENAME}\"\n",
    "echo \"ENDPOINT_ID=${ENDPOINT_ID}\"\n",
    "\n",
    "# Deployment\n",
    "DEPLOYEDMODEL_DISPLAYNAME=${MODEL_DISPLAYNAME}_deployment\n",
    "MACHINE_TYPE=n1-standard-2\n",
    "MIN_REPLICA_COUNT=1\n",
    "MAX_REPLICA_COUNT=3\n",
    "\n",
    "gcloud ai endpoints deploy-model $ENDPOINT_RESOURCENAME \\\n",
    "  --region=$REGION \\\n",
    "  --model=$MODEL_RESOURCENAME \\\n",
    "  --display-name=$DEPLOYEDMODEL_DISPLAYNAME \\\n",
    "  --machine-type=$MACHINE_TYPE \\\n",
    "  --min-replica-count=$MIN_REPLICA_COUNT \\\n",
    "  --max-replica-count=$MAX_REPLICA_COUNT \\\n",
    "  --traffic-split=0=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af715ee-1e87-4fd8-a97d-8b9f2c407a80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
