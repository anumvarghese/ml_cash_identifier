{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df616735-2bae-4947-99bd-cf17b4691f0d",
   "metadata": {},
   "source": [
    "# Note Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a01a0e-a329-4653-93fa-8301d66e63ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Declare Bucket Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57128bbf-49ce-43a6-b4f2-c8f6ba0fdcdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<google.api_core.page_iterator.HTTPIterator object at 0x7f328859e4d0>\n",
      "<Blob: team4-project, imgs/euro/.DS_Store, 1650537665680586>\n",
      "<Blob: team4-project, imgs/euro/full_list.csv, 1650641657886222>\n",
      "<Blob: team4-project, imgs/euro/train_list.csv, 1650641639609143>\n",
      "<Blob: team4-project, imgs/euro/train_set.csv, 1650622880765520>\n",
      "<Blob: team4-project, imgs/euro/val_list.csv, 1650641641574812>\n"
     ]
    }
   ],
   "source": [
    "from google.cloud import storage\n",
    "bucket_name = \"team4-project\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "my_prefix='imgs/euro/'\n",
    "blobs = bucket.list_blobs(prefix = my_prefix, delimiter = '/')\n",
    "print(blobs)\n",
    "for blob in blobs:\n",
    "    print(blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d578e804-9bfe-4909-9835-29f182adfb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all files in teh path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170c590c-848e-4228-b4a9-3c0f6eb3aba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                     0    1\n",
      "0     gs://team4-project/imgs/euro/10/10-Euro-back.jpg   10\n",
      "1          gs://team4-project/imgs/euro/10/10-Euro.jpg   10\n",
      "2    gs://team4-project/imgs/euro/10/10euro_fr_ES1_...   10\n",
      "3    gs://team4-project/imgs/euro/10/10euro_re_ES1_...   10\n",
      "4    gs://team4-project/imgs/euro/10/ECB_10euro_Ban...   10\n",
      "..                                                 ...  ...\n",
      "254  gs://team4-project/imgs/euro/500/Screen Shot 2...  500\n",
      "255  gs://team4-project/imgs/euro/500/Screen Shot 2...  500\n",
      "256  gs://team4-project/imgs/euro/500/Screen Shot 2...  500\n",
      "257  gs://team4-project/imgs/euro/500/Screen Shot 2...  500\n",
      "258  gs://team4-project/imgs/euro/500/Screen Shot 2...  500\n",
      "\n",
      "[259 rows x 2 columns]\n",
      "Copying file://text.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 16.8 KiB/ 16.8 KiB]                                                \n",
      "Operation completed over 1 objects/16.8 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "blobs_all = list(bucket.list_blobs(prefix=my_prefix))\n",
    "data_out=[]\n",
    "for x in blobs_all:\n",
    "    #Select only image files\n",
    "    if x.name.endswith(('.png','.jpg','.jpeg')):\n",
    "        data_out.append(['gs://'+bucket_name+'/'+x.name,x.name.split('/')[-2]])\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acff2ba7-5a0e-4c73-ad10-f64daef466f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export full csv list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae19fc6-5609-4bc8-9bf8-ff94e41e342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data_out)\n",
    "print(df    )     \n",
    "df.to_csv('text.csv', index = False,header=False)\n",
    "full_out_path=f'gs://{bucket_name}/{my_prefix}full_list.csv'\n",
    "!gsutil cp 'text.csv' $full_out_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e192ba-2bf7-4ba4-aa89-58abe6a72322",
   "metadata": {},
   "source": [
    "## Export train and validatino samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46a7724c-593f-4a5b-93b0-b0d8e7691cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://train_data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][ 13.4 KiB/ 13.4 KiB]                                                \n",
      "Operation completed over 1 objects/13.4 KiB.                                     \n",
      "Copying file://val_data.csv [Content-Type=text/csv]...\n",
      "/ [1 files][  3.4 KiB/  3.4 KiB]                                                \n",
      "Operation completed over 1 objects/3.4 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "train_data = df.sample(frac = 0.8)\n",
    "train_data.to_csv('train_data.csv', index = False,header=False)\n",
    "train_out_path=f'gs://{bucket_name}/{my_prefix}train_list.csv'\n",
    "!gsutil cp 'train_data.csv' $train_out_path\n",
    "\n",
    "# Creating dataframe with\n",
    "# rest of the 50% values\n",
    "val_data = df.drop(train_data.index)\n",
    "val_data.to_csv('val_data.csv', index = False,header=False)\n",
    "val_out_path=f'gs://{bucket_name}/{my_prefix}val_list.csv'\n",
    "!gsutil cp 'val_data.csv' $val_out_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88a95264-f4a0-4731-be27-44e073cd8eb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://team4-project/imgs/euro/train_list.csv\n",
      "gs://team4-project/imgs/euro/val_list.csv\n",
      "These are the available classes: ['10' '100' '20' '200' '5' '50' '500']\n"
     ]
    }
   ],
   "source": [
    "train_data_loc=train_out_path\n",
    "val_data_loc = val_out_path\n",
    "CLASS_NAMES = df[1].unique()\n",
    "print(train_data_loc)\n",
    "print(val_data_loc)\n",
    "print(\"These are the available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "830da4ca-d325-4944-a6c9-07c1596514db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are the available classes: ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "train_data_loc=\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/train_set.csv\"\n",
    "val_data_loc=\"gs://practical-ml-vision-book/flowers_5_jpeg/flower_photos/eval_set.csv\"\n",
    "CLASS_NAMES = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "print(\"These are the available classes:\", CLASS_NAMES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74201ec-bafa-4132-b0db-4f19e3343dd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a6a5e87-7bc7-463d-ae85-ae63b43c7c4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\ndevice_name = tf.test.gpu_device_name()\\nif device_name != '/device:GPU:0':\\n    raise SystemError('GPU device not found')\\nprint('Found GPU at: {}'.format(device_name))\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.version.VERSION)\n",
    "#GPU doesn't work!\n",
    "'''\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "    raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e66b8b68-7591-4165-8472-2e95ca6c25e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions\n",
    "def training_plot(metrics, history):\n",
    "  f, ax = plt.subplots(1, len(metrics), figsize=(5*len(metrics), 5))\n",
    "  for idx, metric in enumerate(metrics):\n",
    "    ax[idx].plot(history.history[metric], ls='dashed')\n",
    "    ax[idx].set_xlabel(\"Epochs\")\n",
    "    ax[idx].set_ylabel(metric)\n",
    "    ax[idx].plot(history.history['val_' + metric]);\n",
    "    ax[idx].legend([metric, 'val_' + metric])\n",
    "\n",
    "# Call model.predict() on a few images in the evaluation dataset\n",
    "def plot_predictions(model, filename):\n",
    "  f, ax = plt.subplots(7, 5, figsize=(25,15))\n",
    "  dataset = (tf.data.TextLineDataset(filename).\n",
    "      map(decode_csv))\n",
    "  for idx, (img, label) in enumerate(dataset.take(35)):\n",
    "    ax[idx//5, idx%5].imshow((img.numpy()));\n",
    "    batch_image = tf.reshape(img, [1, IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS])\n",
    "    batch_pred = model.predict(batch_image)\n",
    "    pred = batch_pred[0]\n",
    "    label = CLASS_NAMES[label.numpy()]\n",
    "    pred_label_index = tf.math.argmax(pred).numpy()\n",
    "    pred_label = CLASS_NAMES[pred_label_index]\n",
    "    prob = pred[pred_label_index]\n",
    "    ax[idx//5, idx%5].set_title('{}: {} ({:.4f})'.format(label, pred_label, prob))\n",
    "    ax[idx//5, idx%5].axis('off')\n",
    "\n",
    "def show_trained_weights(model):\n",
    "  # CLASS_NAMES is ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n",
    "  LAYER = 1 # Layer 0 flattens the image, layer=1 is the first dense layer\n",
    "  WEIGHT_TYPE = 0 # 0 for weight, 1 for bias\n",
    "\n",
    "  f, ax = plt.subplots(1, 5, figsize=(15,15))\n",
    "  for flower in range(len(CLASS_NAMES)):\n",
    "    weights = model.layers[LAYER].get_weights()[WEIGHT_TYPE][:, flower]\n",
    "    min_wt = tf.math.reduce_min(weights).numpy()\n",
    "    max_wt = tf.math.reduce_max(weights).numpy()\n",
    "    flower_name = CLASS_NAMES[flower]\n",
    "    print(\"Scaling weights for {} in {} to {}\".format(\n",
    "        flower_name, min_wt, max_wt))\n",
    "    weights = (weights - min_wt)/(max_wt - min_wt)\n",
    "    ax[flower].imshow(weights.reshape(IMG_HEIGHT, IMG_WIDTH, 3));\n",
    "    ax[flower].set_title(flower_name);\n",
    "    ax[flower].axis('off')\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "IMG_HEIGHT = 224\n",
    "IMG_WIDTH = 224\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "def read_and_decode(filename, reshape_dims):\n",
    "  # Read the file\n",
    "  img = tf.io.read_file(filename)\n",
    "  # Convert the compressed string to a 3D uint8 tensor.\n",
    "  img = tf.image.decode_jpeg(img, channels=IMG_CHANNELS)\n",
    "  # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "  img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "  # Resize the image to the desired size.\n",
    "  return tf.image.resize(img, reshape_dims)\n",
    "\n",
    "\n",
    "\n",
    "# the label is the index into CLASS_NAMES array\n",
    "def decode_csv(csv_row):\n",
    "  record_defaults = [\"path\", \"flower\"]\n",
    "  filename, label_string = tf.io.decode_csv(csv_row, record_defaults)\n",
    "  img = read_and_decode(filename, [IMG_HEIGHT, IMG_WIDTH])\n",
    "  label = tf.argmax(tf.math.equal(CLASS_NAMES, label_string))\n",
    "  return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c1edeff-9aa3-4f2d-ba76-90cdd1f9563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_hub as hub\n",
    "import os\n",
    "# Load compressed models from tensorflow_hub\n",
    "os.environ['TFHUB_MODEL_LOAD_FORMAT'] = 'COMPRESSED'\n",
    "\n",
    "# parameterize to the values in the previous cell\n",
    "def train_and_evaluate(batch_size = 32,\n",
    "                       lrate = 0.001,\n",
    "                       l1 = 0.,\n",
    "                       l2 = 0.,\n",
    "                       num_hidden = 16):\n",
    "  regularizer = tf.keras.regularizers.l1_l2(l1, l2)\n",
    "\n",
    "  train_dataset = (tf.data.TextLineDataset(\n",
    "      train_data_loc).\n",
    "      map(decode_csv)).batch(batch_size)\n",
    "\n",
    "  eval_dataset = (tf.data.TextLineDataset(\n",
    "      val_data_loc).\n",
    "      map(decode_csv)).batch(32) # this doesn't matter\n",
    "\n",
    "  layers = [\n",
    "      hub.KerasLayer(\n",
    "          \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\",\n",
    "          input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
    "          trainable=False,\n",
    "          name='mobilenet_embedding'),\n",
    "      tf.keras.layers.Dense(num_hidden,\n",
    "                            kernel_regularizer=regularizer, \n",
    "                            activation='relu',\n",
    "                            name='dense_hidden'),\n",
    "      tf.keras.layers.Dense(len(CLASS_NAMES), \n",
    "                            kernel_regularizer=regularizer,\n",
    "                            activation='softmax',\n",
    "                            name='flower_prob')\n",
    "  ]\n",
    "\n",
    "  model = tf.keras.Sequential(layers, name='flower_classification')\n",
    "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lrate),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                    from_logits=False),\n",
    "                metrics=['accuracy'])\n",
    "  print(model.summary())\n",
    "  history = model.fit(train_dataset, validation_data=eval_dataset, epochs=5)\n",
    "  training_plot(['loss', 'accuracy'], history)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d5961-8611-4333-bbab-58e561e68a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-22 16:02:23.305012: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"flower_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " mobilenet_embedding (KerasL  (None, 1280)             2257984   \n",
      " ayer)                                                           \n",
      "                                                                 \n",
      " dense_hidden (Dense)        (None, 16)                20496     \n",
      "                                                                 \n",
      " flower_prob (Dense)         (None, 5)                 85        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,278,565\n",
      "Trainable params: 20,581\n",
      "Non-trainable params: 2,257,984\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n",
      "104/104 [==============================] - 155s 1s/step - loss: 0.6406 - accuracy: 0.7718 - val_loss: 0.4086 - val_accuracy: 0.8622\n",
      "Epoch 2/5\n",
      " 37/104 [=========>....................] - ETA: 1:24 - loss: 0.3036 - accuracy: 0.8894"
     ]
    }
   ],
   "source": [
    "model = train_and_evaluate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63928e8d-fd10-4e94-9e26-08b8e08aa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(val_data_loc)\n",
    "plot_predictions(model, val_data_loc)"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-8.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-8:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
